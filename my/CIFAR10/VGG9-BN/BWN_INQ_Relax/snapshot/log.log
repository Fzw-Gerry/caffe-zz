I0902 20:35:15.419391 25873 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to my/CIFAR10/VGG9-BN/BWN_INQ_Relax/snapshot/solver
I0902 20:35:15.419643 25873 caffe.cpp:204] Using GPUs 0
I0902 20:35:15.438164 25873 caffe.cpp:209] GPU 0: GeForce GTX TITAN X
I0902 20:35:15.659824 25873 solver.cpp:45] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.005
display: 200
max_iter: 60000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 15000
snapshot: 10000
snapshot_prefix: "my/CIFAR10/VGG9-BN/BWN_INQ_Relax/snapshot/solver"
solver_mode: GPU
device_id: 0
net: "my/CIFAR10/VGG9-BN/BWN_INQ_Relax/train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
weights: "my/CIFAR10/VGG9-BN/BWN_INQ_Relax/VGG9_BN_0.9118.caffemodel"
quantize_phase_ratio: 0.4
quantize_phase_ratio: 0.2
quantize_phase_ratio: 0
isquantize: true
I0902 20:35:15.660073 25873 solver.cpp:105] Creating training net from net file: my/CIFAR10/VGG9-BN/BWN_INQ_Relax/train_test.prototxt
I0902 20:35:15.660655 25873 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0902 20:35:15.660720 25873 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0902 20:35:15.660915 25873 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_vgg"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1_bn"
}
layer {
  name: "bn1_scal"
  type: "Scale"
  bottom: "conv1_bn"
  top: "conv1_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1_sc"
  top: "conv1_sc"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "conv1_sc"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2_bn"
}
layer {
  name: "bn2_scal"
  type: "Scale"
  bottom: "conv2_bn"
  top: "conv2_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2_sc"
  top: "conv2_sc"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv2_sc"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3_bn"
}
layer {
  name: "bn3_scal"
  type: "Scale"
  bottom: "conv3_bn"
  top: "conv3_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3_sc"
  top: "conv3_sc"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3_sc"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4_bn"
}
layer {
  name: "bn4_scal"
  type: "Scale"
  bottom: "conv4_bn"
  top: "conv4_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4_sc"
  top: "conv4_sc"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv4_sc"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "pool2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5_bn"
}
layer {
  name: "bn5_scal"
  type: "Scale"
  bottom: "conv5_bn"
  top: "conv5_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5_sc"
  top: "conv5_sc"
}
layer {
  name: "conv6"
  type: "BinaryConvolution"
  bottom: "conv5_sc"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn6_bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6_bn"
}
layer {
  name: "bn6_scal"
  type: "Scale"
  bottom: "conv6_bn"
  top: "conv6_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6_sc"
  top: "conv6_sc"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv6_sc"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "pool3"
  top: "pool3"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "pool3"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn7_bn"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7_bn"
}
layer {
  name: "bn7_scal"
  type: "Scale"
  bottom: "fc7_bn"
  top: "fc7_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7_sc"
  top: "fc7_sc"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_sc"
  top: "fc7_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7_sc"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn8_bn"
  type: "BatchNorm"
  bottom: "fc8"
  top: "fc8_bn"
}
layer {
  name: "bn8_scal"
  type: "Scale"
  bottom: "fc8_bn"
  top: "fc8_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "fc8_sc"
  top: "fc8_sc"
}
layer {
  name: "drop8"
  type: "Dropout"
  bottom: "fc8_sc"
  top: "fc8_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc9"
  type: "BinaryInnerProduct"
  bottom: "fc8_sc"
  top: "fc9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0902 20:35:15.661525 25873 layer_factory.hpp:77] Creating layer cifar
I0902 20:35:15.661697 25873 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0902 20:35:15.661747 25873 net.cpp:84] Creating Layer cifar
I0902 20:35:15.661770 25873 net.cpp:380] cifar -> data
I0902 20:35:15.661888 25873 net.cpp:380] cifar -> label
I0902 20:35:15.661926 25873 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0902 20:35:15.663158 25873 data_layer.cpp:45] output data size: 100,3,32,32
I0902 20:35:15.665892 25873 base_data_layer.cpp:72] Initializing prefetch
I0902 20:35:15.666014 25873 base_data_layer.cpp:75] Prefetch initialized.
I0902 20:35:15.666033 25873 net.cpp:122] Setting up cifar
I0902 20:35:15.666072 25873 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0902 20:35:15.666081 25873 net.cpp:129] Top shape: 100 (100)
I0902 20:35:15.666085 25873 net.cpp:137] Memory required for data: 1229200
I0902 20:35:15.666105 25873 layer_factory.hpp:77] Creating layer conv1
I0902 20:35:15.666189 25873 net.cpp:84] Creating Layer conv1
I0902 20:35:15.666219 25873 net.cpp:406] conv1 <- data
I0902 20:35:15.666263 25873 net.cpp:380] conv1 -> conv1
I0902 20:35:15.666893 25873 net.cpp:122] Setting up conv1
I0902 20:35:15.666908 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:15.666913 25873 net.cpp:137] Memory required for data: 27443600
I0902 20:35:15.666955 25873 layer_factory.hpp:77] Creating layer bn1_bn
I0902 20:35:15.666978 25873 net.cpp:84] Creating Layer bn1_bn
I0902 20:35:15.666987 25873 net.cpp:406] bn1_bn <- conv1
I0902 20:35:15.667002 25873 net.cpp:380] bn1_bn -> conv1_bn
I0902 20:35:15.667578 25873 net.cpp:122] Setting up bn1_bn
I0902 20:35:15.667595 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:15.667600 25873 net.cpp:137] Memory required for data: 53658000
I0902 20:35:15.667636 25873 layer_factory.hpp:77] Creating layer bn1_scal
I0902 20:35:15.667661 25873 net.cpp:84] Creating Layer bn1_scal
I0902 20:35:15.667670 25873 net.cpp:406] bn1_scal <- conv1_bn
I0902 20:35:15.667690 25873 net.cpp:380] bn1_scal -> conv1_sc
I0902 20:35:15.667763 25873 layer_factory.hpp:77] Creating layer bn1_scal
I0902 20:35:15.667913 25873 net.cpp:122] Setting up bn1_scal
I0902 20:35:15.667927 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:15.667934 25873 net.cpp:137] Memory required for data: 79872400
I0902 20:35:15.667956 25873 layer_factory.hpp:77] Creating layer relu1
I0902 20:35:15.667979 25873 net.cpp:84] Creating Layer relu1
I0902 20:35:15.667987 25873 net.cpp:406] relu1 <- conv1_sc
I0902 20:35:15.668001 25873 net.cpp:367] relu1 -> conv1_sc (in-place)
I0902 20:35:16.066695 25873 net.cpp:122] Setting up relu1
I0902 20:35:16.066730 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.066736 25873 net.cpp:137] Memory required for data: 106086800
I0902 20:35:16.066752 25873 layer_factory.hpp:77] Creating layer conv2
I0902 20:35:16.066845 25873 net.cpp:84] Creating Layer conv2
I0902 20:35:16.066872 25873 net.cpp:406] conv2 <- conv1_sc
I0902 20:35:16.066944 25873 net.cpp:380] conv2 -> conv2
I0902 20:35:16.072280 25873 net.cpp:122] Setting up conv2
I0902 20:35:16.072300 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.072304 25873 net.cpp:137] Memory required for data: 132301200
I0902 20:35:16.072320 25873 layer_factory.hpp:77] Creating layer bn2_bn
I0902 20:35:16.072356 25873 net.cpp:84] Creating Layer bn2_bn
I0902 20:35:16.072366 25873 net.cpp:406] bn2_bn <- conv2
I0902 20:35:16.072392 25873 net.cpp:380] bn2_bn -> conv2_bn
I0902 20:35:16.072630 25873 net.cpp:122] Setting up bn2_bn
I0902 20:35:16.072643 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.072646 25873 net.cpp:137] Memory required for data: 158515600
I0902 20:35:16.072687 25873 layer_factory.hpp:77] Creating layer bn2_scal
I0902 20:35:16.072718 25873 net.cpp:84] Creating Layer bn2_scal
I0902 20:35:16.072754 25873 net.cpp:406] bn2_scal <- conv2_bn
I0902 20:35:16.072788 25873 net.cpp:380] bn2_scal -> conv2_sc
I0902 20:35:16.072896 25873 layer_factory.hpp:77] Creating layer bn2_scal
I0902 20:35:16.073082 25873 net.cpp:122] Setting up bn2_scal
I0902 20:35:16.073094 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.073108 25873 net.cpp:137] Memory required for data: 184730000
I0902 20:35:16.073122 25873 layer_factory.hpp:77] Creating layer relu2
I0902 20:35:16.073143 25873 net.cpp:84] Creating Layer relu2
I0902 20:35:16.073149 25873 net.cpp:406] relu2 <- conv2_sc
I0902 20:35:16.073181 25873 net.cpp:367] relu2 -> conv2_sc (in-place)
I0902 20:35:16.073520 25873 net.cpp:122] Setting up relu2
I0902 20:35:16.073531 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.073536 25873 net.cpp:137] Memory required for data: 210944400
I0902 20:35:16.073542 25873 layer_factory.hpp:77] Creating layer pool1
I0902 20:35:16.073568 25873 net.cpp:84] Creating Layer pool1
I0902 20:35:16.073577 25873 net.cpp:406] pool1 <- conv2_sc
I0902 20:35:16.073595 25873 net.cpp:380] pool1 -> pool1
I0902 20:35:16.073668 25873 net.cpp:122] Setting up pool1
I0902 20:35:16.073679 25873 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0902 20:35:16.073684 25873 net.cpp:137] Memory required for data: 217498000
I0902 20:35:16.073690 25873 layer_factory.hpp:77] Creating layer drop1
I0902 20:35:16.073709 25873 net.cpp:84] Creating Layer drop1
I0902 20:35:16.073726 25873 net.cpp:406] drop1 <- pool1
I0902 20:35:16.073750 25873 net.cpp:367] drop1 -> pool1 (in-place)
I0902 20:35:16.073788 25873 net.cpp:122] Setting up drop1
I0902 20:35:16.073797 25873 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0902 20:35:16.073802 25873 net.cpp:137] Memory required for data: 224051600
I0902 20:35:16.073807 25873 layer_factory.hpp:77] Creating layer conv3
I0902 20:35:16.073827 25873 net.cpp:84] Creating Layer conv3
I0902 20:35:16.073835 25873 net.cpp:406] conv3 <- pool1
I0902 20:35:16.073853 25873 net.cpp:380] conv3 -> conv3
I0902 20:35:16.084043 25873 net.cpp:122] Setting up conv3
I0902 20:35:16.084060 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.084065 25873 net.cpp:137] Memory required for data: 237158800
I0902 20:35:16.084079 25873 layer_factory.hpp:77] Creating layer bn3_bn
I0902 20:35:16.084103 25873 net.cpp:84] Creating Layer bn3_bn
I0902 20:35:16.084113 25873 net.cpp:406] bn3_bn <- conv3
I0902 20:35:16.084139 25873 net.cpp:380] bn3_bn -> conv3_bn
I0902 20:35:16.084347 25873 net.cpp:122] Setting up bn3_bn
I0902 20:35:16.084357 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.084362 25873 net.cpp:137] Memory required for data: 250266000
I0902 20:35:16.084380 25873 layer_factory.hpp:77] Creating layer bn3_scal
I0902 20:35:16.084395 25873 net.cpp:84] Creating Layer bn3_scal
I0902 20:35:16.084403 25873 net.cpp:406] bn3_scal <- conv3_bn
I0902 20:35:16.084419 25873 net.cpp:380] bn3_scal -> conv3_sc
I0902 20:35:16.084481 25873 layer_factory.hpp:77] Creating layer bn3_scal
I0902 20:35:16.084617 25873 net.cpp:122] Setting up bn3_scal
I0902 20:35:16.084630 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.084633 25873 net.cpp:137] Memory required for data: 263373200
I0902 20:35:16.084656 25873 layer_factory.hpp:77] Creating layer relu3
I0902 20:35:16.084671 25873 net.cpp:84] Creating Layer relu3
I0902 20:35:16.084678 25873 net.cpp:406] relu3 <- conv3_sc
I0902 20:35:16.084692 25873 net.cpp:367] relu3 -> conv3_sc (in-place)
I0902 20:35:16.085166 25873 net.cpp:122] Setting up relu3
I0902 20:35:16.085177 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.085182 25873 net.cpp:137] Memory required for data: 276480400
I0902 20:35:16.085188 25873 layer_factory.hpp:77] Creating layer conv4
I0902 20:35:16.085208 25873 net.cpp:84] Creating Layer conv4
I0902 20:35:16.085217 25873 net.cpp:406] conv4 <- conv3_sc
I0902 20:35:16.085237 25873 net.cpp:380] conv4 -> conv4
I0902 20:35:16.104027 25873 net.cpp:122] Setting up conv4
I0902 20:35:16.104043 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.104060 25873 net.cpp:137] Memory required for data: 289587600
I0902 20:35:16.104082 25873 layer_factory.hpp:77] Creating layer bn4_bn
I0902 20:35:16.104107 25873 net.cpp:84] Creating Layer bn4_bn
I0902 20:35:16.104135 25873 net.cpp:406] bn4_bn <- conv4
I0902 20:35:16.104161 25873 net.cpp:380] bn4_bn -> conv4_bn
I0902 20:35:16.104401 25873 net.cpp:122] Setting up bn4_bn
I0902 20:35:16.104413 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.104416 25873 net.cpp:137] Memory required for data: 302694800
I0902 20:35:16.104435 25873 layer_factory.hpp:77] Creating layer bn4_scal
I0902 20:35:16.104459 25873 net.cpp:84] Creating Layer bn4_scal
I0902 20:35:16.104485 25873 net.cpp:406] bn4_scal <- conv4_bn
I0902 20:35:16.104501 25873 net.cpp:380] bn4_scal -> conv4_sc
I0902 20:35:16.104583 25873 layer_factory.hpp:77] Creating layer bn4_scal
I0902 20:35:16.104722 25873 net.cpp:122] Setting up bn4_scal
I0902 20:35:16.104733 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.104737 25873 net.cpp:137] Memory required for data: 315802000
I0902 20:35:16.104750 25873 layer_factory.hpp:77] Creating layer relu4
I0902 20:35:16.104763 25873 net.cpp:84] Creating Layer relu4
I0902 20:35:16.104771 25873 net.cpp:406] relu4 <- conv4_sc
I0902 20:35:16.104794 25873 net.cpp:367] relu4 -> conv4_sc (in-place)
I0902 20:35:16.105144 25873 net.cpp:122] Setting up relu4
I0902 20:35:16.105154 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.105159 25873 net.cpp:137] Memory required for data: 328909200
I0902 20:35:16.105165 25873 layer_factory.hpp:77] Creating layer pool2
I0902 20:35:16.105191 25873 net.cpp:84] Creating Layer pool2
I0902 20:35:16.105199 25873 net.cpp:406] pool2 <- conv4_sc
I0902 20:35:16.105217 25873 net.cpp:380] pool2 -> pool2
I0902 20:35:16.105298 25873 net.cpp:122] Setting up pool2
I0902 20:35:16.105319 25873 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0902 20:35:16.105332 25873 net.cpp:137] Memory required for data: 332186000
I0902 20:35:16.105340 25873 layer_factory.hpp:77] Creating layer drop2
I0902 20:35:16.105355 25873 net.cpp:84] Creating Layer drop2
I0902 20:35:16.105362 25873 net.cpp:406] drop2 <- pool2
I0902 20:35:16.105376 25873 net.cpp:367] drop2 -> pool2 (in-place)
I0902 20:35:16.105414 25873 net.cpp:122] Setting up drop2
I0902 20:35:16.105423 25873 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0902 20:35:16.105428 25873 net.cpp:137] Memory required for data: 335462800
I0902 20:35:16.105433 25873 layer_factory.hpp:77] Creating layer conv5
I0902 20:35:16.105454 25873 net.cpp:84] Creating Layer conv5
I0902 20:35:16.105463 25873 net.cpp:406] conv5 <- pool2
I0902 20:35:16.105482 25873 net.cpp:380] conv5 -> conv5
I0902 20:35:16.143541 25873 net.cpp:122] Setting up conv5
I0902 20:35:16.143563 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.143566 25873 net.cpp:137] Memory required for data: 342016400
I0902 20:35:16.143581 25873 layer_factory.hpp:77] Creating layer bn5_bn
I0902 20:35:16.143618 25873 net.cpp:84] Creating Layer bn5_bn
I0902 20:35:16.143630 25873 net.cpp:406] bn5_bn <- conv5
I0902 20:35:16.143658 25873 net.cpp:380] bn5_bn -> conv5_bn
I0902 20:35:16.143932 25873 net.cpp:122] Setting up bn5_bn
I0902 20:35:16.143944 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.143949 25873 net.cpp:137] Memory required for data: 348570000
I0902 20:35:16.143967 25873 layer_factory.hpp:77] Creating layer bn5_scal
I0902 20:35:16.143991 25873 net.cpp:84] Creating Layer bn5_scal
I0902 20:35:16.143999 25873 net.cpp:406] bn5_scal <- conv5_bn
I0902 20:35:16.144014 25873 net.cpp:380] bn5_scal -> conv5_sc
I0902 20:35:16.144094 25873 layer_factory.hpp:77] Creating layer bn5_scal
I0902 20:35:16.144260 25873 net.cpp:122] Setting up bn5_scal
I0902 20:35:16.144273 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.144276 25873 net.cpp:137] Memory required for data: 355123600
I0902 20:35:16.144289 25873 layer_factory.hpp:77] Creating layer relu5
I0902 20:35:16.144311 25873 net.cpp:84] Creating Layer relu5
I0902 20:35:16.144330 25873 net.cpp:406] relu5 <- conv5_sc
I0902 20:35:16.144347 25873 net.cpp:367] relu5 -> conv5_sc (in-place)
I0902 20:35:16.144897 25873 net.cpp:122] Setting up relu5
I0902 20:35:16.144908 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.144912 25873 net.cpp:137] Memory required for data: 361677200
I0902 20:35:16.144919 25873 layer_factory.hpp:77] Creating layer conv6
I0902 20:35:16.144942 25873 net.cpp:84] Creating Layer conv6
I0902 20:35:16.144951 25873 net.cpp:406] conv6 <- conv5_sc
I0902 20:35:16.144973 25873 net.cpp:380] conv6 -> conv6
I0902 20:35:16.218045 25873 net.cpp:122] Setting up conv6
I0902 20:35:16.218070 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.218073 25873 net.cpp:137] Memory required for data: 368230800
I0902 20:35:16.218091 25873 layer_factory.hpp:77] Creating layer bn6_bn
I0902 20:35:16.218132 25873 net.cpp:84] Creating Layer bn6_bn
I0902 20:35:16.218144 25873 net.cpp:406] bn6_bn <- conv6
I0902 20:35:16.218174 25873 net.cpp:380] bn6_bn -> conv6_bn
I0902 20:35:16.218448 25873 net.cpp:122] Setting up bn6_bn
I0902 20:35:16.218459 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.218463 25873 net.cpp:137] Memory required for data: 374784400
I0902 20:35:16.218506 25873 layer_factory.hpp:77] Creating layer bn6_scal
I0902 20:35:16.218528 25873 net.cpp:84] Creating Layer bn6_scal
I0902 20:35:16.218535 25873 net.cpp:406] bn6_scal <- conv6_bn
I0902 20:35:16.218560 25873 net.cpp:380] bn6_scal -> conv6_sc
I0902 20:35:16.218667 25873 layer_factory.hpp:77] Creating layer bn6_scal
I0902 20:35:16.218858 25873 net.cpp:122] Setting up bn6_scal
I0902 20:35:16.218870 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.218874 25873 net.cpp:137] Memory required for data: 381338000
I0902 20:35:16.218888 25873 layer_factory.hpp:77] Creating layer relu6
I0902 20:35:16.218901 25873 net.cpp:84] Creating Layer relu6
I0902 20:35:16.218910 25873 net.cpp:406] relu6 <- conv6_sc
I0902 20:35:16.218924 25873 net.cpp:367] relu6 -> conv6_sc (in-place)
I0902 20:35:16.219507 25873 net.cpp:122] Setting up relu6
I0902 20:35:16.219518 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.219522 25873 net.cpp:137] Memory required for data: 387891600
I0902 20:35:16.219528 25873 layer_factory.hpp:77] Creating layer pool3
I0902 20:35:16.219548 25873 net.cpp:84] Creating Layer pool3
I0902 20:35:16.219558 25873 net.cpp:406] pool3 <- conv6_sc
I0902 20:35:16.219573 25873 net.cpp:380] pool3 -> pool3
I0902 20:35:16.219636 25873 net.cpp:122] Setting up pool3
I0902 20:35:16.219648 25873 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0902 20:35:16.219652 25873 net.cpp:137] Memory required for data: 389530000
I0902 20:35:16.219657 25873 layer_factory.hpp:77] Creating layer drop3
I0902 20:35:16.219672 25873 net.cpp:84] Creating Layer drop3
I0902 20:35:16.219681 25873 net.cpp:406] drop3 <- pool3
I0902 20:35:16.219696 25873 net.cpp:367] drop3 -> pool3 (in-place)
I0902 20:35:16.219733 25873 net.cpp:122] Setting up drop3
I0902 20:35:16.219744 25873 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0902 20:35:16.219748 25873 net.cpp:137] Memory required for data: 391168400
I0902 20:35:16.219755 25873 layer_factory.hpp:77] Creating layer fc7
I0902 20:35:16.219782 25873 net.cpp:84] Creating Layer fc7
I0902 20:35:16.219790 25873 net.cpp:406] fc7 <- pool3
I0902 20:35:16.219810 25873 net.cpp:380] fc7 -> fc7
I0902 20:35:16.478207 25873 net.cpp:122] Setting up fc7
I0902 20:35:16.478242 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.478247 25873 net.cpp:137] Memory required for data: 391373200
I0902 20:35:16.478284 25873 layer_factory.hpp:77] Creating layer bn7_bn
I0902 20:35:16.478358 25873 net.cpp:84] Creating Layer bn7_bn
I0902 20:35:16.478382 25873 net.cpp:406] bn7_bn <- fc7
I0902 20:35:16.478418 25873 net.cpp:380] bn7_bn -> fc7_bn
I0902 20:35:16.478710 25873 net.cpp:122] Setting up bn7_bn
I0902 20:35:16.478724 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.478727 25873 net.cpp:137] Memory required for data: 391578000
I0902 20:35:16.478773 25873 layer_factory.hpp:77] Creating layer bn7_scal
I0902 20:35:16.478807 25873 net.cpp:84] Creating Layer bn7_scal
I0902 20:35:16.478816 25873 net.cpp:406] bn7_scal <- fc7_bn
I0902 20:35:16.478843 25873 net.cpp:380] bn7_scal -> fc7_sc
I0902 20:35:16.478936 25873 layer_factory.hpp:77] Creating layer bn7_scal
I0902 20:35:16.479115 25873 net.cpp:122] Setting up bn7_scal
I0902 20:35:16.479125 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.479130 25873 net.cpp:137] Memory required for data: 391782800
I0902 20:35:16.479142 25873 layer_factory.hpp:77] Creating layer relu7
I0902 20:35:16.479163 25873 net.cpp:84] Creating Layer relu7
I0902 20:35:16.479173 25873 net.cpp:406] relu7 <- fc7_sc
I0902 20:35:16.479197 25873 net.cpp:367] relu7 -> fc7_sc (in-place)
I0902 20:35:16.479640 25873 net.cpp:122] Setting up relu7
I0902 20:35:16.479651 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.479655 25873 net.cpp:137] Memory required for data: 391987600
I0902 20:35:16.479660 25873 layer_factory.hpp:77] Creating layer drop7
I0902 20:35:16.479677 25873 net.cpp:84] Creating Layer drop7
I0902 20:35:16.479686 25873 net.cpp:406] drop7 <- fc7_sc
I0902 20:35:16.479702 25873 net.cpp:367] drop7 -> fc7_sc (in-place)
I0902 20:35:16.479739 25873 net.cpp:122] Setting up drop7
I0902 20:35:16.479748 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.479753 25873 net.cpp:137] Memory required for data: 392192400
I0902 20:35:16.479758 25873 layer_factory.hpp:77] Creating layer fc8
I0902 20:35:16.479782 25873 net.cpp:84] Creating Layer fc8
I0902 20:35:16.479791 25873 net.cpp:406] fc8 <- fc7_sc
I0902 20:35:16.479811 25873 net.cpp:380] fc8 -> fc8
I0902 20:35:16.513317 25873 net.cpp:122] Setting up fc8
I0902 20:35:16.513339 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.513352 25873 net.cpp:137] Memory required for data: 392397200
I0902 20:35:16.513381 25873 layer_factory.hpp:77] Creating layer bn8_bn
I0902 20:35:16.513413 25873 net.cpp:84] Creating Layer bn8_bn
I0902 20:35:16.513423 25873 net.cpp:406] bn8_bn <- fc8
I0902 20:35:16.513459 25873 net.cpp:380] bn8_bn -> fc8_bn
I0902 20:35:16.513686 25873 net.cpp:122] Setting up bn8_bn
I0902 20:35:16.513697 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.513702 25873 net.cpp:137] Memory required for data: 392602000
I0902 20:35:16.513721 25873 layer_factory.hpp:77] Creating layer bn8_scal
I0902 20:35:16.513747 25873 net.cpp:84] Creating Layer bn8_scal
I0902 20:35:16.513756 25873 net.cpp:406] bn8_scal <- fc8_bn
I0902 20:35:16.513772 25873 net.cpp:380] bn8_scal -> fc8_sc
I0902 20:35:16.513850 25873 layer_factory.hpp:77] Creating layer bn8_scal
I0902 20:35:16.514025 25873 net.cpp:122] Setting up bn8_scal
I0902 20:35:16.514037 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.514042 25873 net.cpp:137] Memory required for data: 392806800
I0902 20:35:16.514055 25873 layer_factory.hpp:77] Creating layer relu8
I0902 20:35:16.514078 25873 net.cpp:84] Creating Layer relu8
I0902 20:35:16.514086 25873 net.cpp:406] relu8 <- fc8_sc
I0902 20:35:16.514101 25873 net.cpp:367] relu8 -> fc8_sc (in-place)
I0902 20:35:16.514717 25873 net.cpp:122] Setting up relu8
I0902 20:35:16.514729 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.514734 25873 net.cpp:137] Memory required for data: 393011600
I0902 20:35:16.514740 25873 layer_factory.hpp:77] Creating layer drop8
I0902 20:35:16.514757 25873 net.cpp:84] Creating Layer drop8
I0902 20:35:16.514775 25873 net.cpp:406] drop8 <- fc8_sc
I0902 20:35:16.514801 25873 net.cpp:367] drop8 -> fc8_sc (in-place)
I0902 20:35:16.514842 25873 net.cpp:122] Setting up drop8
I0902 20:35:16.514852 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:16.514855 25873 net.cpp:137] Memory required for data: 393216400
I0902 20:35:16.514861 25873 layer_factory.hpp:77] Creating layer fc9
I0902 20:35:16.514883 25873 net.cpp:84] Creating Layer fc9
I0902 20:35:16.514892 25873 net.cpp:406] fc9 <- fc8_sc
I0902 20:35:16.514932 25873 net.cpp:380] fc9 -> fc9
I0902 20:35:16.516197 25873 net.cpp:122] Setting up fc9
I0902 20:35:16.516224 25873 net.cpp:129] Top shape: 100 10 (1000)
I0902 20:35:16.516230 25873 net.cpp:137] Memory required for data: 393220400
I0902 20:35:16.516248 25873 layer_factory.hpp:77] Creating layer loss
I0902 20:35:16.516273 25873 net.cpp:84] Creating Layer loss
I0902 20:35:16.516281 25873 net.cpp:406] loss <- fc9
I0902 20:35:16.516296 25873 net.cpp:406] loss <- label
I0902 20:35:16.516315 25873 net.cpp:380] loss -> loss
I0902 20:35:16.516338 25873 layer_factory.hpp:77] Creating layer loss
I0902 20:35:16.516829 25873 net.cpp:122] Setting up loss
I0902 20:35:16.516841 25873 net.cpp:129] Top shape: (1)
I0902 20:35:16.516846 25873 net.cpp:132]     with loss weight 1
I0902 20:35:16.516872 25873 net.cpp:137] Memory required for data: 393220404
I0902 20:35:16.516882 25873 net.cpp:198] loss needs backward computation.
I0902 20:35:16.516893 25873 net.cpp:198] fc9 needs backward computation.
I0902 20:35:16.516901 25873 net.cpp:198] drop8 needs backward computation.
I0902 20:35:16.516908 25873 net.cpp:198] relu8 needs backward computation.
I0902 20:35:16.516916 25873 net.cpp:198] bn8_scal needs backward computation.
I0902 20:35:16.516923 25873 net.cpp:198] bn8_bn needs backward computation.
I0902 20:35:16.516930 25873 net.cpp:198] fc8 needs backward computation.
I0902 20:35:16.516938 25873 net.cpp:198] drop7 needs backward computation.
I0902 20:35:16.516945 25873 net.cpp:198] relu7 needs backward computation.
I0902 20:35:16.516950 25873 net.cpp:198] bn7_scal needs backward computation.
I0902 20:35:16.516958 25873 net.cpp:198] bn7_bn needs backward computation.
I0902 20:35:16.516965 25873 net.cpp:198] fc7 needs backward computation.
I0902 20:35:16.516973 25873 net.cpp:198] drop3 needs backward computation.
I0902 20:35:16.516980 25873 net.cpp:198] pool3 needs backward computation.
I0902 20:35:16.516988 25873 net.cpp:198] relu6 needs backward computation.
I0902 20:35:16.516993 25873 net.cpp:198] bn6_scal needs backward computation.
I0902 20:35:16.517001 25873 net.cpp:198] bn6_bn needs backward computation.
I0902 20:35:16.517009 25873 net.cpp:198] conv6 needs backward computation.
I0902 20:35:16.517015 25873 net.cpp:198] relu5 needs backward computation.
I0902 20:35:16.517021 25873 net.cpp:198] bn5_scal needs backward computation.
I0902 20:35:16.517027 25873 net.cpp:198] bn5_bn needs backward computation.
I0902 20:35:16.517035 25873 net.cpp:198] conv5 needs backward computation.
I0902 20:35:16.517041 25873 net.cpp:198] drop2 needs backward computation.
I0902 20:35:16.517047 25873 net.cpp:198] pool2 needs backward computation.
I0902 20:35:16.517055 25873 net.cpp:198] relu4 needs backward computation.
I0902 20:35:16.517060 25873 net.cpp:198] bn4_scal needs backward computation.
I0902 20:35:16.517067 25873 net.cpp:198] bn4_bn needs backward computation.
I0902 20:35:16.517073 25873 net.cpp:198] conv4 needs backward computation.
I0902 20:35:16.517081 25873 net.cpp:198] relu3 needs backward computation.
I0902 20:35:16.517087 25873 net.cpp:198] bn3_scal needs backward computation.
I0902 20:35:16.517096 25873 net.cpp:198] bn3_bn needs backward computation.
I0902 20:35:16.517102 25873 net.cpp:198] conv3 needs backward computation.
I0902 20:35:16.517108 25873 net.cpp:198] drop1 needs backward computation.
I0902 20:35:16.517113 25873 net.cpp:198] pool1 needs backward computation.
I0902 20:35:16.517122 25873 net.cpp:198] relu2 needs backward computation.
I0902 20:35:16.517128 25873 net.cpp:198] bn2_scal needs backward computation.
I0902 20:35:16.517134 25873 net.cpp:198] bn2_bn needs backward computation.
I0902 20:35:16.517141 25873 net.cpp:198] conv2 needs backward computation.
I0902 20:35:16.517148 25873 net.cpp:198] relu1 needs backward computation.
I0902 20:35:16.517155 25873 net.cpp:198] bn1_scal needs backward computation.
I0902 20:35:16.517163 25873 net.cpp:198] bn1_bn needs backward computation.
I0902 20:35:16.517168 25873 net.cpp:198] conv1 needs backward computation.
I0902 20:35:16.517176 25873 net.cpp:200] cifar does not need backward computation.
I0902 20:35:16.517184 25873 net.cpp:242] This network produces output loss
I0902 20:35:16.517252 25873 net.cpp:255] Network initialization done.
I0902 20:35:16.517489 25873 solver.cpp:75] Finetuning from my/CIFAR10/VGG9-BN/BWN_INQ_Relax/VGG9_BN_0.9118.caffemodel
I0902 20:35:16.532830 25873 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: my/CIFAR10/VGG9-BN/BWN_INQ_Relax/VGG9_BN_0.9118.caffemodel
I0902 20:35:16.532876 25873 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0902 20:35:16.532894 25873 net.cpp:811] net quantization's state : 0
I0902 20:35:16.532907 25873 net.cpp:824] Copying source layer cifar
I0902 20:35:16.532912 25873 net.cpp:824] Copying source layer conv1
I0902 20:35:16.533162 25873 net.cpp:824] Copying source layer bn1_bn
I0902 20:35:16.533288 25873 net.cpp:824] Copying source layer bn1_scal
I0902 20:35:16.533344 25873 net.cpp:824] Copying source layer relu1
I0902 20:35:16.533360 25873 net.cpp:824] Copying source layer conv2
I0902 20:35:16.533983 25873 net.cpp:824] Copying source layer bn2_bn
I0902 20:35:16.534060 25873 net.cpp:824] Copying source layer bn2_scal
I0902 20:35:16.534122 25873 net.cpp:824] Copying source layer relu2
I0902 20:35:16.534129 25873 net.cpp:824] Copying source layer pool1
I0902 20:35:16.534133 25873 net.cpp:824] Copying source layer drop1
I0902 20:35:16.534137 25873 net.cpp:824] Copying source layer conv3
I0902 20:35:16.535751 25873 net.cpp:824] Copying source layer bn3_bn
I0902 20:35:16.535835 25873 net.cpp:824] Copying source layer bn3_scal
I0902 20:35:16.535897 25873 net.cpp:824] Copying source layer relu3
I0902 20:35:16.535912 25873 net.cpp:824] Copying source layer conv4
I0902 20:35:16.538163 25873 net.cpp:824] Copying source layer bn4_bn
I0902 20:35:16.538240 25873 net.cpp:824] Copying source layer bn4_scal
I0902 20:35:16.538290 25873 net.cpp:824] Copying source layer relu4
I0902 20:35:16.538297 25873 net.cpp:824] Copying source layer pool2
I0902 20:35:16.538301 25873 net.cpp:824] Copying source layer drop2
I0902 20:35:16.538306 25873 net.cpp:824] Copying source layer conv5
I0902 20:35:16.543246 25873 net.cpp:824] Copying source layer bn5_bn
I0902 20:35:16.543388 25873 net.cpp:824] Copying source layer bn5_scal
I0902 20:35:16.543467 25873 net.cpp:824] Copying source layer relu5
I0902 20:35:16.543475 25873 net.cpp:824] Copying source layer conv6
I0902 20:35:16.552822 25873 net.cpp:824] Copying source layer bn6_bn
I0902 20:35:16.552979 25873 net.cpp:824] Copying source layer bn6_scal
I0902 20:35:16.553035 25873 net.cpp:824] Copying source layer relu6
I0902 20:35:16.553061 25873 net.cpp:824] Copying source layer pool3
I0902 20:35:16.553066 25873 net.cpp:824] Copying source layer drop3
I0902 20:35:16.553071 25873 net.cpp:824] Copying source layer fc7
I0902 20:35:16.587142 25873 net.cpp:824] Copying source layer bn7_bn
I0902 20:35:16.587363 25873 net.cpp:824] Copying source layer bn7_scal
I0902 20:35:16.587430 25873 net.cpp:824] Copying source layer relu7
I0902 20:35:16.587440 25873 net.cpp:824] Copying source layer drop7
I0902 20:35:16.587445 25873 net.cpp:824] Copying source layer fc8
I0902 20:35:16.591799 25873 net.cpp:824] Copying source layer bn8_bn
I0902 20:35:16.591928 25873 net.cpp:824] Copying source layer bn8_scal
I0902 20:35:16.592032 25873 net.cpp:824] Copying source layer relu8
I0902 20:35:16.592041 25873 net.cpp:824] Copying source layer drop8
I0902 20:35:16.592054 25873 net.cpp:824] Copying source layer fc9
I0902 20:35:16.592221 25873 net.cpp:824] Copying source layer loss
I0902 20:35:16.592669 25873 solver.cpp:193] Creating test net (#0) specified by net file: my/CIFAR10/VGG9-BN/BWN_INQ_Relax/train_test.prototxt
I0902 20:35:16.592830 25873 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0902 20:35:16.593075 25873 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_vgg"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1_bn"
}
layer {
  name: "bn1_scal"
  type: "Scale"
  bottom: "conv1_bn"
  top: "conv1_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1_sc"
  top: "conv1_sc"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "conv1_sc"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2_bn"
}
layer {
  name: "bn2_scal"
  type: "Scale"
  bottom: "conv2_bn"
  top: "conv2_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2_sc"
  top: "conv2_sc"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv2_sc"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3_bn"
}
layer {
  name: "bn3_scal"
  type: "Scale"
  bottom: "conv3_bn"
  top: "conv3_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3_sc"
  top: "conv3_sc"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3_sc"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4_bn"
}
layer {
  name: "bn4_scal"
  type: "Scale"
  bottom: "conv4_bn"
  top: "conv4_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4_sc"
  top: "conv4_sc"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv4_sc"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "pool2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5_bn"
}
layer {
  name: "bn5_scal"
  type: "Scale"
  bottom: "conv5_bn"
  top: "conv5_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5_sc"
  top: "conv5_sc"
}
layer {
  name: "conv6"
  type: "BinaryConvolution"
  bottom: "conv5_sc"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn6_bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6_bn"
}
layer {
  name: "bn6_scal"
  type: "Scale"
  bottom: "conv6_bn"
  top: "conv6_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6_sc"
  top: "conv6_sc"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv6_sc"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "pool3"
  top: "pool3"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "pool3"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn7_bn"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7_bn"
}
layer {
  name: "bn7_scal"
  type: "Scale"
  bottom: "fc7_bn"
  top: "fc7_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7_sc"
  top: "fc7_sc"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_sc"
  top: "fc7_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7_sc"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "bn8_bn"
  type: "BatchNorm"
  bottom: "fc8"
  top: "fc8_bn"
}
layer {
  name: "bn8_scal"
  type: "Scale"
  bottom: "fc8_bn"
  top: "fc8_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "fc8_sc"
  top: "fc8_sc"
}
layer {
  name: "drop8"
  type: "Dropout"
  bottom: "fc8_sc"
  top: "fc8_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc9"
  type: "BinaryInnerProduct"
  bottom: "fc8_sc"
  top: "fc9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.01
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc9"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0902 20:35:16.593601 25873 layer_factory.hpp:77] Creating layer cifar
I0902 20:35:16.593722 25873 db_lmdb.cpp:35] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0902 20:35:16.593745 25873 net.cpp:84] Creating Layer cifar
I0902 20:35:16.593758 25873 net.cpp:380] cifar -> data
I0902 20:35:16.593832 25873 net.cpp:380] cifar -> label
I0902 20:35:16.593863 25873 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0902 20:35:16.594161 25873 data_layer.cpp:45] output data size: 100,3,32,32
I0902 20:35:16.597519 25873 base_data_layer.cpp:72] Initializing prefetch
I0902 20:35:16.597574 25873 base_data_layer.cpp:75] Prefetch initialized.
I0902 20:35:16.597591 25873 net.cpp:122] Setting up cifar
I0902 20:35:16.597611 25873 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0902 20:35:16.597618 25873 net.cpp:129] Top shape: 100 (100)
I0902 20:35:16.597622 25873 net.cpp:137] Memory required for data: 1229200
I0902 20:35:16.597642 25873 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0902 20:35:16.597671 25873 net.cpp:84] Creating Layer label_cifar_1_split
I0902 20:35:16.597690 25873 net.cpp:406] label_cifar_1_split <- label
I0902 20:35:16.597718 25873 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0902 20:35:16.597765 25873 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0902 20:35:16.597865 25873 net.cpp:122] Setting up label_cifar_1_split
I0902 20:35:16.597877 25873 net.cpp:129] Top shape: 100 (100)
I0902 20:35:16.597884 25873 net.cpp:129] Top shape: 100 (100)
I0902 20:35:16.597887 25873 net.cpp:137] Memory required for data: 1230000
I0902 20:35:16.597893 25873 layer_factory.hpp:77] Creating layer conv1
I0902 20:35:16.597936 25873 net.cpp:84] Creating Layer conv1
I0902 20:35:16.597954 25873 net.cpp:406] conv1 <- data
I0902 20:35:16.597973 25873 net.cpp:380] conv1 -> conv1
I0902 20:35:16.598616 25873 net.cpp:122] Setting up conv1
I0902 20:35:16.598629 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.598635 25873 net.cpp:137] Memory required for data: 27444400
I0902 20:35:16.598656 25873 layer_factory.hpp:77] Creating layer bn1_bn
I0902 20:35:16.598672 25873 net.cpp:84] Creating Layer bn1_bn
I0902 20:35:16.598680 25873 net.cpp:406] bn1_bn <- conv1
I0902 20:35:16.598695 25873 net.cpp:380] bn1_bn -> conv1_bn
I0902 20:35:16.598950 25873 net.cpp:122] Setting up bn1_bn
I0902 20:35:16.598964 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.598969 25873 net.cpp:137] Memory required for data: 53658800
I0902 20:35:16.599001 25873 layer_factory.hpp:77] Creating layer bn1_scal
I0902 20:35:16.599021 25873 net.cpp:84] Creating Layer bn1_scal
I0902 20:35:16.599030 25873 net.cpp:406] bn1_scal <- conv1_bn
I0902 20:35:16.599046 25873 net.cpp:380] bn1_scal -> conv1_sc
I0902 20:35:16.599113 25873 layer_factory.hpp:77] Creating layer bn1_scal
I0902 20:35:16.599274 25873 net.cpp:122] Setting up bn1_scal
I0902 20:35:16.599287 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.599292 25873 net.cpp:137] Memory required for data: 79873200
I0902 20:35:16.599313 25873 layer_factory.hpp:77] Creating layer relu1
I0902 20:35:16.599328 25873 net.cpp:84] Creating Layer relu1
I0902 20:35:16.599337 25873 net.cpp:406] relu1 <- conv1_sc
I0902 20:35:16.599351 25873 net.cpp:367] relu1 -> conv1_sc (in-place)
I0902 20:35:16.599829 25873 net.cpp:122] Setting up relu1
I0902 20:35:16.599843 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.599848 25873 net.cpp:137] Memory required for data: 106087600
I0902 20:35:16.599854 25873 layer_factory.hpp:77] Creating layer conv2
I0902 20:35:16.599874 25873 net.cpp:84] Creating Layer conv2
I0902 20:35:16.599887 25873 net.cpp:406] conv2 <- conv1_sc
I0902 20:35:16.599908 25873 net.cpp:380] conv2 -> conv2
I0902 20:35:16.604990 25873 net.cpp:122] Setting up conv2
I0902 20:35:16.605005 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.605010 25873 net.cpp:137] Memory required for data: 132302000
I0902 20:35:16.605021 25873 layer_factory.hpp:77] Creating layer bn2_bn
I0902 20:35:16.605036 25873 net.cpp:84] Creating Layer bn2_bn
I0902 20:35:16.605044 25873 net.cpp:406] bn2_bn <- conv2
I0902 20:35:16.605059 25873 net.cpp:380] bn2_bn -> conv2_bn
I0902 20:35:16.605314 25873 net.cpp:122] Setting up bn2_bn
I0902 20:35:16.605325 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.605330 25873 net.cpp:137] Memory required for data: 158516400
I0902 20:35:16.605358 25873 layer_factory.hpp:77] Creating layer bn2_scal
I0902 20:35:16.605377 25873 net.cpp:84] Creating Layer bn2_scal
I0902 20:35:16.605386 25873 net.cpp:406] bn2_scal <- conv2_bn
I0902 20:35:16.605402 25873 net.cpp:380] bn2_scal -> conv2_sc
I0902 20:35:16.605469 25873 layer_factory.hpp:77] Creating layer bn2_scal
I0902 20:35:16.605631 25873 net.cpp:122] Setting up bn2_scal
I0902 20:35:16.605643 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.605648 25873 net.cpp:137] Memory required for data: 184730800
I0902 20:35:16.605661 25873 layer_factory.hpp:77] Creating layer relu2
I0902 20:35:16.605675 25873 net.cpp:84] Creating Layer relu2
I0902 20:35:16.605684 25873 net.cpp:406] relu2 <- conv2_sc
I0902 20:35:16.605696 25873 net.cpp:367] relu2 -> conv2_sc (in-place)
I0902 20:35:16.606204 25873 net.cpp:122] Setting up relu2
I0902 20:35:16.606216 25873 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0902 20:35:16.606221 25873 net.cpp:137] Memory required for data: 210945200
I0902 20:35:16.606227 25873 layer_factory.hpp:77] Creating layer pool1
I0902 20:35:16.606246 25873 net.cpp:84] Creating Layer pool1
I0902 20:35:16.606256 25873 net.cpp:406] pool1 <- conv2_sc
I0902 20:35:16.606272 25873 net.cpp:380] pool1 -> pool1
I0902 20:35:16.606365 25873 net.cpp:122] Setting up pool1
I0902 20:35:16.606377 25873 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0902 20:35:16.606382 25873 net.cpp:137] Memory required for data: 217498800
I0902 20:35:16.606392 25873 layer_factory.hpp:77] Creating layer drop1
I0902 20:35:16.606407 25873 net.cpp:84] Creating Layer drop1
I0902 20:35:16.606415 25873 net.cpp:406] drop1 <- pool1
I0902 20:35:16.606431 25873 net.cpp:367] drop1 -> pool1 (in-place)
I0902 20:35:16.606472 25873 net.cpp:122] Setting up drop1
I0902 20:35:16.606480 25873 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0902 20:35:16.606484 25873 net.cpp:137] Memory required for data: 224052400
I0902 20:35:16.606490 25873 layer_factory.hpp:77] Creating layer conv3
I0902 20:35:16.606508 25873 net.cpp:84] Creating Layer conv3
I0902 20:35:16.606518 25873 net.cpp:406] conv3 <- pool1
I0902 20:35:16.606535 25873 net.cpp:380] conv3 -> conv3
I0902 20:35:16.616681 25873 net.cpp:122] Setting up conv3
I0902 20:35:16.616715 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.616720 25873 net.cpp:137] Memory required for data: 237159600
I0902 20:35:16.616749 25873 layer_factory.hpp:77] Creating layer bn3_bn
I0902 20:35:16.616773 25873 net.cpp:84] Creating Layer bn3_bn
I0902 20:35:16.616811 25873 net.cpp:406] bn3_bn <- conv3
I0902 20:35:16.616842 25873 net.cpp:380] bn3_bn -> conv3_bn
I0902 20:35:16.617084 25873 net.cpp:122] Setting up bn3_bn
I0902 20:35:16.617095 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.617110 25873 net.cpp:137] Memory required for data: 250266800
I0902 20:35:16.617130 25873 layer_factory.hpp:77] Creating layer bn3_scal
I0902 20:35:16.617148 25873 net.cpp:84] Creating Layer bn3_scal
I0902 20:35:16.617156 25873 net.cpp:406] bn3_scal <- conv3_bn
I0902 20:35:16.617172 25873 net.cpp:380] bn3_scal -> conv3_sc
I0902 20:35:16.617252 25873 layer_factory.hpp:77] Creating layer bn3_scal
I0902 20:35:16.617420 25873 net.cpp:122] Setting up bn3_scal
I0902 20:35:16.617432 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.617446 25873 net.cpp:137] Memory required for data: 263374000
I0902 20:35:16.617471 25873 layer_factory.hpp:77] Creating layer relu3
I0902 20:35:16.617486 25873 net.cpp:84] Creating Layer relu3
I0902 20:35:16.617493 25873 net.cpp:406] relu3 <- conv3_sc
I0902 20:35:16.617507 25873 net.cpp:367] relu3 -> conv3_sc (in-place)
I0902 20:35:16.617887 25873 net.cpp:122] Setting up relu3
I0902 20:35:16.617897 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.617902 25873 net.cpp:137] Memory required for data: 276481200
I0902 20:35:16.617908 25873 layer_factory.hpp:77] Creating layer conv4
I0902 20:35:16.617936 25873 net.cpp:84] Creating Layer conv4
I0902 20:35:16.617945 25873 net.cpp:406] conv4 <- conv3_sc
I0902 20:35:16.617965 25873 net.cpp:380] conv4 -> conv4
I0902 20:35:16.636700 25873 net.cpp:122] Setting up conv4
I0902 20:35:16.636713 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.636716 25873 net.cpp:137] Memory required for data: 289588400
I0902 20:35:16.636728 25873 layer_factory.hpp:77] Creating layer bn4_bn
I0902 20:35:16.636739 25873 net.cpp:84] Creating Layer bn4_bn
I0902 20:35:16.636754 25873 net.cpp:406] bn4_bn <- conv4
I0902 20:35:16.636770 25873 net.cpp:380] bn4_bn -> conv4_bn
I0902 20:35:16.637025 25873 net.cpp:122] Setting up bn4_bn
I0902 20:35:16.637037 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.637040 25873 net.cpp:137] Memory required for data: 302695600
I0902 20:35:16.637058 25873 layer_factory.hpp:77] Creating layer bn4_scal
I0902 20:35:16.637081 25873 net.cpp:84] Creating Layer bn4_scal
I0902 20:35:16.637109 25873 net.cpp:406] bn4_scal <- conv4_bn
I0902 20:35:16.637143 25873 net.cpp:380] bn4_scal -> conv4_sc
I0902 20:35:16.637226 25873 layer_factory.hpp:77] Creating layer bn4_scal
I0902 20:35:16.637387 25873 net.cpp:122] Setting up bn4_scal
I0902 20:35:16.637398 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.637413 25873 net.cpp:137] Memory required for data: 315802800
I0902 20:35:16.637425 25873 layer_factory.hpp:77] Creating layer relu4
I0902 20:35:16.637437 25873 net.cpp:84] Creating Layer relu4
I0902 20:35:16.637445 25873 net.cpp:406] relu4 <- conv4_sc
I0902 20:35:16.637459 25873 net.cpp:367] relu4 -> conv4_sc (in-place)
I0902 20:35:16.637976 25873 net.cpp:122] Setting up relu4
I0902 20:35:16.637989 25873 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0902 20:35:16.637993 25873 net.cpp:137] Memory required for data: 328910000
I0902 20:35:16.638000 25873 layer_factory.hpp:77] Creating layer pool2
I0902 20:35:16.638017 25873 net.cpp:84] Creating Layer pool2
I0902 20:35:16.638025 25873 net.cpp:406] pool2 <- conv4_sc
I0902 20:35:16.638042 25873 net.cpp:380] pool2 -> pool2
I0902 20:35:16.638103 25873 net.cpp:122] Setting up pool2
I0902 20:35:16.638113 25873 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0902 20:35:16.638118 25873 net.cpp:137] Memory required for data: 332186800
I0902 20:35:16.638123 25873 layer_factory.hpp:77] Creating layer drop2
I0902 20:35:16.638139 25873 net.cpp:84] Creating Layer drop2
I0902 20:35:16.638146 25873 net.cpp:406] drop2 <- pool2
I0902 20:35:16.638160 25873 net.cpp:367] drop2 -> pool2 (in-place)
I0902 20:35:16.638196 25873 net.cpp:122] Setting up drop2
I0902 20:35:16.638206 25873 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0902 20:35:16.638209 25873 net.cpp:137] Memory required for data: 335463600
I0902 20:35:16.638216 25873 layer_factory.hpp:77] Creating layer conv5
I0902 20:35:16.638232 25873 net.cpp:84] Creating Layer conv5
I0902 20:35:16.638240 25873 net.cpp:406] conv5 <- pool2
I0902 20:35:16.638258 25873 net.cpp:380] conv5 -> conv5
I0902 20:35:16.675582 25873 net.cpp:122] Setting up conv5
I0902 20:35:16.675616 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.675619 25873 net.cpp:137] Memory required for data: 342017200
I0902 20:35:16.675652 25873 layer_factory.hpp:77] Creating layer bn5_bn
I0902 20:35:16.675698 25873 net.cpp:84] Creating Layer bn5_bn
I0902 20:35:16.675738 25873 net.cpp:406] bn5_bn <- conv5
I0902 20:35:16.675771 25873 net.cpp:380] bn5_bn -> conv5_bn
I0902 20:35:16.676048 25873 net.cpp:122] Setting up bn5_bn
I0902 20:35:16.676059 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.676064 25873 net.cpp:137] Memory required for data: 348570800
I0902 20:35:16.676082 25873 layer_factory.hpp:77] Creating layer bn5_scal
I0902 20:35:16.676100 25873 net.cpp:84] Creating Layer bn5_scal
I0902 20:35:16.676107 25873 net.cpp:406] bn5_scal <- conv5_bn
I0902 20:35:16.676131 25873 net.cpp:380] bn5_scal -> conv5_sc
I0902 20:35:16.676230 25873 layer_factory.hpp:77] Creating layer bn5_scal
I0902 20:35:16.676384 25873 net.cpp:122] Setting up bn5_scal
I0902 20:35:16.676395 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.676399 25873 net.cpp:137] Memory required for data: 355124400
I0902 20:35:16.676414 25873 layer_factory.hpp:77] Creating layer relu5
I0902 20:35:16.676425 25873 net.cpp:84] Creating Layer relu5
I0902 20:35:16.676434 25873 net.cpp:406] relu5 <- conv5_sc
I0902 20:35:16.676457 25873 net.cpp:367] relu5 -> conv5_sc (in-place)
I0902 20:35:16.676857 25873 net.cpp:122] Setting up relu5
I0902 20:35:16.676868 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.676872 25873 net.cpp:137] Memory required for data: 361678000
I0902 20:35:16.676888 25873 layer_factory.hpp:77] Creating layer conv6
I0902 20:35:16.676913 25873 net.cpp:84] Creating Layer conv6
I0902 20:35:16.676930 25873 net.cpp:406] conv6 <- conv5_sc
I0902 20:35:16.676966 25873 net.cpp:380] conv6 -> conv6
I0902 20:35:16.750653 25873 net.cpp:122] Setting up conv6
I0902 20:35:16.750686 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.750720 25873 net.cpp:137] Memory required for data: 368231600
I0902 20:35:16.750756 25873 layer_factory.hpp:77] Creating layer bn6_bn
I0902 20:35:16.750797 25873 net.cpp:84] Creating Layer bn6_bn
I0902 20:35:16.750810 25873 net.cpp:406] bn6_bn <- conv6
I0902 20:35:16.750852 25873 net.cpp:380] bn6_bn -> conv6_bn
I0902 20:35:16.751142 25873 net.cpp:122] Setting up bn6_bn
I0902 20:35:16.751163 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.751166 25873 net.cpp:137] Memory required for data: 374785200
I0902 20:35:16.751230 25873 layer_factory.hpp:77] Creating layer bn6_scal
I0902 20:35:16.751250 25873 net.cpp:84] Creating Layer bn6_scal
I0902 20:35:16.751256 25873 net.cpp:406] bn6_scal <- conv6_bn
I0902 20:35:16.751281 25873 net.cpp:380] bn6_scal -> conv6_sc
I0902 20:35:16.751392 25873 layer_factory.hpp:77] Creating layer bn6_scal
I0902 20:35:16.751581 25873 net.cpp:122] Setting up bn6_scal
I0902 20:35:16.751602 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.751606 25873 net.cpp:137] Memory required for data: 381338800
I0902 20:35:16.751628 25873 layer_factory.hpp:77] Creating layer relu6
I0902 20:35:16.751642 25873 net.cpp:84] Creating Layer relu6
I0902 20:35:16.751652 25873 net.cpp:406] relu6 <- conv6_sc
I0902 20:35:16.751683 25873 net.cpp:367] relu6 -> conv6_sc (in-place)
I0902 20:35:16.752283 25873 net.cpp:122] Setting up relu6
I0902 20:35:16.752295 25873 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0902 20:35:16.752300 25873 net.cpp:137] Memory required for data: 387892400
I0902 20:35:16.752305 25873 layer_factory.hpp:77] Creating layer pool3
I0902 20:35:16.752324 25873 net.cpp:84] Creating Layer pool3
I0902 20:35:16.752332 25873 net.cpp:406] pool3 <- conv6_sc
I0902 20:35:16.752348 25873 net.cpp:380] pool3 -> pool3
I0902 20:35:16.752413 25873 net.cpp:122] Setting up pool3
I0902 20:35:16.752424 25873 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0902 20:35:16.752429 25873 net.cpp:137] Memory required for data: 389530800
I0902 20:35:16.752434 25873 layer_factory.hpp:77] Creating layer drop3
I0902 20:35:16.752449 25873 net.cpp:84] Creating Layer drop3
I0902 20:35:16.752456 25873 net.cpp:406] drop3 <- pool3
I0902 20:35:16.752470 25873 net.cpp:367] drop3 -> pool3 (in-place)
I0902 20:35:16.752507 25873 net.cpp:122] Setting up drop3
I0902 20:35:16.752516 25873 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0902 20:35:16.752521 25873 net.cpp:137] Memory required for data: 391169200
I0902 20:35:16.752527 25873 layer_factory.hpp:77] Creating layer fc7
I0902 20:35:16.752557 25873 net.cpp:84] Creating Layer fc7
I0902 20:35:16.752565 25873 net.cpp:406] fc7 <- pool3
I0902 20:35:16.752584 25873 net.cpp:380] fc7 -> fc7
I0902 20:35:17.011221 25873 net.cpp:122] Setting up fc7
I0902 20:35:17.011257 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.011262 25873 net.cpp:137] Memory required for data: 391374000
I0902 20:35:17.011298 25873 layer_factory.hpp:77] Creating layer bn7_bn
I0902 20:35:17.011348 25873 net.cpp:84] Creating Layer bn7_bn
I0902 20:35:17.011370 25873 net.cpp:406] bn7_bn <- fc7
I0902 20:35:17.011413 25873 net.cpp:380] bn7_bn -> fc7_bn
I0902 20:35:17.011687 25873 net.cpp:122] Setting up bn7_bn
I0902 20:35:17.011698 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.011701 25873 net.cpp:137] Memory required for data: 391578800
I0902 20:35:17.011720 25873 layer_factory.hpp:77] Creating layer bn7_scal
I0902 20:35:17.011747 25873 net.cpp:84] Creating Layer bn7_scal
I0902 20:35:17.011775 25873 net.cpp:406] bn7_scal <- fc7_bn
I0902 20:35:17.011790 25873 net.cpp:380] bn7_scal -> fc7_sc
I0902 20:35:17.011883 25873 layer_factory.hpp:77] Creating layer bn7_scal
I0902 20:35:17.012059 25873 net.cpp:122] Setting up bn7_scal
I0902 20:35:17.012070 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.012074 25873 net.cpp:137] Memory required for data: 391783600
I0902 20:35:17.012087 25873 layer_factory.hpp:77] Creating layer relu7
I0902 20:35:17.012109 25873 net.cpp:84] Creating Layer relu7
I0902 20:35:17.012116 25873 net.cpp:406] relu7 <- fc7_sc
I0902 20:35:17.012171 25873 net.cpp:367] relu7 -> fc7_sc (in-place)
I0902 20:35:17.012778 25873 net.cpp:122] Setting up relu7
I0902 20:35:17.012789 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.012794 25873 net.cpp:137] Memory required for data: 391988400
I0902 20:35:17.012800 25873 layer_factory.hpp:77] Creating layer drop7
I0902 20:35:17.012816 25873 net.cpp:84] Creating Layer drop7
I0902 20:35:17.012825 25873 net.cpp:406] drop7 <- fc7_sc
I0902 20:35:17.012840 25873 net.cpp:367] drop7 -> fc7_sc (in-place)
I0902 20:35:17.012879 25873 net.cpp:122] Setting up drop7
I0902 20:35:17.012888 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.012892 25873 net.cpp:137] Memory required for data: 392193200
I0902 20:35:17.012897 25873 layer_factory.hpp:77] Creating layer fc8
I0902 20:35:17.012920 25873 net.cpp:84] Creating Layer fc8
I0902 20:35:17.012928 25873 net.cpp:406] fc8 <- fc7_sc
I0902 20:35:17.012948 25873 net.cpp:380] fc8 -> fc8
I0902 20:35:17.046712 25873 net.cpp:122] Setting up fc8
I0902 20:35:17.046738 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.046742 25873 net.cpp:137] Memory required for data: 392398000
I0902 20:35:17.046772 25873 layer_factory.hpp:77] Creating layer bn8_bn
I0902 20:35:17.046799 25873 net.cpp:84] Creating Layer bn8_bn
I0902 20:35:17.046820 25873 net.cpp:406] bn8_bn <- fc8
I0902 20:35:17.046851 25873 net.cpp:380] bn8_bn -> fc8_bn
I0902 20:35:17.047101 25873 net.cpp:122] Setting up bn8_bn
I0902 20:35:17.047113 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.047130 25873 net.cpp:137] Memory required for data: 392602800
I0902 20:35:17.047168 25873 layer_factory.hpp:77] Creating layer bn8_scal
I0902 20:35:17.047185 25873 net.cpp:84] Creating Layer bn8_scal
I0902 20:35:17.047194 25873 net.cpp:406] bn8_scal <- fc8_bn
I0902 20:35:17.047209 25873 net.cpp:380] bn8_scal -> fc8_sc
I0902 20:35:17.047288 25873 layer_factory.hpp:77] Creating layer bn8_scal
I0902 20:35:17.047467 25873 net.cpp:122] Setting up bn8_scal
I0902 20:35:17.047479 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.047497 25873 net.cpp:137] Memory required for data: 392807600
I0902 20:35:17.047528 25873 layer_factory.hpp:77] Creating layer relu8
I0902 20:35:17.047541 25873 net.cpp:84] Creating Layer relu8
I0902 20:35:17.047550 25873 net.cpp:406] relu8 <- fc8_sc
I0902 20:35:17.047564 25873 net.cpp:367] relu8 -> fc8_sc (in-place)
I0902 20:35:17.047955 25873 net.cpp:122] Setting up relu8
I0902 20:35:17.047973 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.047978 25873 net.cpp:137] Memory required for data: 393012400
I0902 20:35:17.047983 25873 layer_factory.hpp:77] Creating layer drop8
I0902 20:35:17.048007 25873 net.cpp:84] Creating Layer drop8
I0902 20:35:17.048017 25873 net.cpp:406] drop8 <- fc8_sc
I0902 20:35:17.048030 25873 net.cpp:367] drop8 -> fc8_sc (in-place)
I0902 20:35:17.048069 25873 net.cpp:122] Setting up drop8
I0902 20:35:17.048079 25873 net.cpp:129] Top shape: 100 512 (51200)
I0902 20:35:17.048082 25873 net.cpp:137] Memory required for data: 393217200
I0902 20:35:17.048089 25873 layer_factory.hpp:77] Creating layer fc9
I0902 20:35:17.048108 25873 net.cpp:84] Creating Layer fc9
I0902 20:35:17.048116 25873 net.cpp:406] fc9 <- fc8_sc
I0902 20:35:17.048133 25873 net.cpp:380] fc9 -> fc9
I0902 20:35:17.049033 25873 net.cpp:122] Setting up fc9
I0902 20:35:17.049046 25873 net.cpp:129] Top shape: 100 10 (1000)
I0902 20:35:17.049051 25873 net.cpp:137] Memory required for data: 393221200
I0902 20:35:17.049064 25873 layer_factory.hpp:77] Creating layer fc9_fc9_0_split
I0902 20:35:17.049078 25873 net.cpp:84] Creating Layer fc9_fc9_0_split
I0902 20:35:17.049087 25873 net.cpp:406] fc9_fc9_0_split <- fc9
I0902 20:35:17.049101 25873 net.cpp:380] fc9_fc9_0_split -> fc9_fc9_0_split_0
I0902 20:35:17.049126 25873 net.cpp:380] fc9_fc9_0_split -> fc9_fc9_0_split_1
I0902 20:35:17.049180 25873 net.cpp:122] Setting up fc9_fc9_0_split
I0902 20:35:17.049192 25873 net.cpp:129] Top shape: 100 10 (1000)
I0902 20:35:17.049198 25873 net.cpp:129] Top shape: 100 10 (1000)
I0902 20:35:17.049213 25873 net.cpp:137] Memory required for data: 393229200
I0902 20:35:17.049221 25873 layer_factory.hpp:77] Creating layer accuracy
I0902 20:35:17.049242 25873 net.cpp:84] Creating Layer accuracy
I0902 20:35:17.049252 25873 net.cpp:406] accuracy <- fc9_fc9_0_split_0
I0902 20:35:17.049264 25873 net.cpp:406] accuracy <- label_cifar_1_split_0
I0902 20:35:17.049278 25873 net.cpp:380] accuracy -> accuracy
I0902 20:35:17.049304 25873 net.cpp:122] Setting up accuracy
I0902 20:35:17.049312 25873 net.cpp:129] Top shape: (1)
I0902 20:35:17.049317 25873 net.cpp:137] Memory required for data: 393229204
I0902 20:35:17.049322 25873 layer_factory.hpp:77] Creating layer loss
I0902 20:35:17.049335 25873 net.cpp:84] Creating Layer loss
I0902 20:35:17.049343 25873 net.cpp:406] loss <- fc9_fc9_0_split_1
I0902 20:35:17.049355 25873 net.cpp:406] loss <- label_cifar_1_split_1
I0902 20:35:17.049368 25873 net.cpp:380] loss -> loss
I0902 20:35:17.049386 25873 layer_factory.hpp:77] Creating layer loss
I0902 20:35:17.050017 25873 net.cpp:122] Setting up loss
I0902 20:35:17.050030 25873 net.cpp:129] Top shape: (1)
I0902 20:35:17.050035 25873 net.cpp:132]     with loss weight 1
I0902 20:35:17.050047 25873 net.cpp:137] Memory required for data: 393229208
I0902 20:35:17.050055 25873 net.cpp:198] loss needs backward computation.
I0902 20:35:17.050065 25873 net.cpp:200] accuracy does not need backward computation.
I0902 20:35:17.050072 25873 net.cpp:198] fc9_fc9_0_split needs backward computation.
I0902 20:35:17.050078 25873 net.cpp:198] fc9 needs backward computation.
I0902 20:35:17.050084 25873 net.cpp:198] drop8 needs backward computation.
I0902 20:35:17.050091 25873 net.cpp:198] relu8 needs backward computation.
I0902 20:35:17.050096 25873 net.cpp:198] bn8_scal needs backward computation.
I0902 20:35:17.050101 25873 net.cpp:198] bn8_bn needs backward computation.
I0902 20:35:17.050107 25873 net.cpp:198] fc8 needs backward computation.
I0902 20:35:17.050114 25873 net.cpp:198] drop7 needs backward computation.
I0902 20:35:17.050120 25873 net.cpp:198] relu7 needs backward computation.
I0902 20:35:17.050125 25873 net.cpp:198] bn7_scal needs backward computation.
I0902 20:35:17.050132 25873 net.cpp:198] bn7_bn needs backward computation.
I0902 20:35:17.050138 25873 net.cpp:198] fc7 needs backward computation.
I0902 20:35:17.050145 25873 net.cpp:198] drop3 needs backward computation.
I0902 20:35:17.050150 25873 net.cpp:198] pool3 needs backward computation.
I0902 20:35:17.050158 25873 net.cpp:198] relu6 needs backward computation.
I0902 20:35:17.050163 25873 net.cpp:198] bn6_scal needs backward computation.
I0902 20:35:17.050170 25873 net.cpp:198] bn6_bn needs backward computation.
I0902 20:35:17.050177 25873 net.cpp:198] conv6 needs backward computation.
I0902 20:35:17.050184 25873 net.cpp:198] relu5 needs backward computation.
I0902 20:35:17.050189 25873 net.cpp:198] bn5_scal needs backward computation.
I0902 20:35:17.050196 25873 net.cpp:198] bn5_bn needs backward computation.
I0902 20:35:17.050202 25873 net.cpp:198] conv5 needs backward computation.
I0902 20:35:17.050209 25873 net.cpp:198] drop2 needs backward computation.
I0902 20:35:17.050215 25873 net.cpp:198] pool2 needs backward computation.
I0902 20:35:17.050222 25873 net.cpp:198] relu4 needs backward computation.
I0902 20:35:17.050228 25873 net.cpp:198] bn4_scal needs backward computation.
I0902 20:35:17.050235 25873 net.cpp:198] bn4_bn needs backward computation.
I0902 20:35:17.050241 25873 net.cpp:198] conv4 needs backward computation.
I0902 20:35:17.050247 25873 net.cpp:198] relu3 needs backward computation.
I0902 20:35:17.050253 25873 net.cpp:198] bn3_scal needs backward computation.
I0902 20:35:17.050261 25873 net.cpp:198] bn3_bn needs backward computation.
I0902 20:35:17.050266 25873 net.cpp:198] conv3 needs backward computation.
I0902 20:35:17.050273 25873 net.cpp:198] drop1 needs backward computation.
I0902 20:35:17.050279 25873 net.cpp:198] pool1 needs backward computation.
I0902 20:35:17.050285 25873 net.cpp:198] relu2 needs backward computation.
I0902 20:35:17.050300 25873 net.cpp:198] bn2_scal needs backward computation.
I0902 20:35:17.050307 25873 net.cpp:198] bn2_bn needs backward computation.
I0902 20:35:17.050314 25873 net.cpp:198] conv2 needs backward computation.
I0902 20:35:17.050321 25873 net.cpp:198] relu1 needs backward computation.
I0902 20:35:17.050328 25873 net.cpp:198] bn1_scal needs backward computation.
I0902 20:35:17.050334 25873 net.cpp:198] bn1_bn needs backward computation.
I0902 20:35:17.050340 25873 net.cpp:198] conv1 needs backward computation.
I0902 20:35:17.050348 25873 net.cpp:200] label_cifar_1_split does not need backward computation.
I0902 20:35:17.050356 25873 net.cpp:200] cifar does not need backward computation.
I0902 20:35:17.050361 25873 net.cpp:242] This network produces output accuracy
I0902 20:35:17.050369 25873 net.cpp:242] This network produces output loss
I0902 20:35:17.050437 25873 net.cpp:255] Network initialization done.
I0902 20:35:17.050559 25873 solver.cpp:75] Finetuning from my/CIFAR10/VGG9-BN/BWN_INQ_Relax/VGG9_BN_0.9118.caffemodel
I0902 20:35:17.061267 25873 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: my/CIFAR10/VGG9-BN/BWN_INQ_Relax/VGG9_BN_0.9118.caffemodel
I0902 20:35:17.061312 25873 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0902 20:35:17.061317 25873 net.cpp:811] net quantization's state : 0
I0902 20:35:17.061322 25873 net.cpp:824] Copying source layer cifar
I0902 20:35:17.061328 25873 net.cpp:824] Copying source layer conv1
I0902 20:35:17.061514 25873 net.cpp:824] Copying source layer bn1_bn
I0902 20:35:17.061619 25873 net.cpp:824] Copying source layer bn1_scal
I0902 20:35:17.061676 25873 net.cpp:824] Copying source layer relu1
I0902 20:35:17.061691 25873 net.cpp:824] Copying source layer conv2
I0902 20:35:17.062280 25873 net.cpp:824] Copying source layer bn2_bn
I0902 20:35:17.062366 25873 net.cpp:824] Copying source layer bn2_scal
I0902 20:35:17.062420 25873 net.cpp:824] Copying source layer relu2
I0902 20:35:17.062436 25873 net.cpp:824] Copying source layer pool1
I0902 20:35:17.062449 25873 net.cpp:824] Copying source layer drop1
I0902 20:35:17.062453 25873 net.cpp:824] Copying source layer conv3
I0902 20:35:17.064043 25873 net.cpp:824] Copying source layer bn3_bn
I0902 20:35:17.064110 25873 net.cpp:824] Copying source layer bn3_scal
I0902 20:35:17.064153 25873 net.cpp:824] Copying source layer relu3
I0902 20:35:17.064160 25873 net.cpp:824] Copying source layer conv4
I0902 20:35:17.066326 25873 net.cpp:824] Copying source layer bn4_bn
I0902 20:35:17.066403 25873 net.cpp:824] Copying source layer bn4_scal
I0902 20:35:17.066454 25873 net.cpp:824] Copying source layer relu4
I0902 20:35:17.066462 25873 net.cpp:824] Copying source layer pool2
I0902 20:35:17.066467 25873 net.cpp:824] Copying source layer drop2
I0902 20:35:17.066470 25873 net.cpp:824] Copying source layer conv5
I0902 20:35:17.071099 25873 net.cpp:824] Copying source layer bn5_bn
I0902 20:35:17.071221 25873 net.cpp:824] Copying source layer bn5_scal
I0902 20:35:17.071288 25873 net.cpp:824] Copying source layer relu5
I0902 20:35:17.071296 25873 net.cpp:824] Copying source layer conv6
I0902 20:35:17.080538 25873 net.cpp:824] Copying source layer bn6_bn
I0902 20:35:17.080678 25873 net.cpp:824] Copying source layer bn6_scal
I0902 20:35:17.080726 25873 net.cpp:824] Copying source layer relu6
I0902 20:35:17.080734 25873 net.cpp:824] Copying source layer pool3
I0902 20:35:17.080739 25873 net.cpp:824] Copying source layer drop3
I0902 20:35:17.080744 25873 net.cpp:824] Copying source layer fc7
I0902 20:35:17.115996 25873 net.cpp:824] Copying source layer bn7_bn
I0902 20:35:17.116235 25873 net.cpp:824] Copying source layer bn7_scal
I0902 20:35:17.116319 25873 net.cpp:824] Copying source layer relu7
I0902 20:35:17.116338 25873 net.cpp:824] Copying source layer drop7
I0902 20:35:17.116343 25873 net.cpp:824] Copying source layer fc8
I0902 20:35:17.120697 25873 net.cpp:824] Copying source layer bn8_bn
I0902 20:35:17.120831 25873 net.cpp:824] Copying source layer bn8_scal
I0902 20:35:17.120915 25873 net.cpp:824] Copying source layer relu8
I0902 20:35:17.120932 25873 net.cpp:824] Copying source layer drop8
I0902 20:35:17.120939 25873 net.cpp:824] Copying source layer fc9
I0902 20:35:17.121091 25873 net.cpp:824] Copying source layer loss
I0902 20:35:17.121237 25873 solver.cpp:57] Solver scaffolding done.
I0902 20:35:17.123375 25873 caffe.cpp:239] Starting Optimization
I0902 20:35:17.123386 25873 solver.cpp:296] Solving CIFAR10_vgg
I0902 20:35:17.123389 25873 solver.cpp:297] Learning Rate Policy: step
I0902 20:35:17.124984 25873 solver.cpp:377] Iteration 0, Testing net (#0)
I0902 20:35:31.403365 25881 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:35:31.992226 25873 solver.cpp:445]     Test net output #0: accuracy = 0.1
I0902 20:35:31.992259 25873 solver.cpp:445]     Test net output #1: loss = 3.93982 (* 1 = 3.93982 loss)
I0902 20:35:31.992264 25873 solver.cpp:456] ================================
I0902 20:35:31.992267 25873 solver.cpp:457]     Test net best accuracy1 is: 0.1
I0902 20:35:32.459509 25873 solver.cpp:242] Iteration 0 (1.87695e-19 iter/s, 15.3358s/200 iters), loss = 1.66911
I0902 20:35:32.459558 25873 solver.cpp:261]     Train net output #0: loss = 1.66911 (* 1 = 1.66911 loss)
I0902 20:35:32.459576 25873 sgd_solver.cpp:122] Iteration 0, lr = 0.005
I0902 20:37:05.004657 25873 solver.cpp:242] Iteration 200 (2.16114 iter/s, 92.5436s/200 iters), loss = 0.351884
I0902 20:37:05.004755 25873 solver.cpp:261]     Train net output #0: loss = 0.351885 (* 1 = 0.351885 loss)
I0902 20:37:05.004776 25873 sgd_solver.cpp:122] Iteration 200, lr = 0.005
I0902 20:38:38.104285 25873 solver.cpp:242] Iteration 400 (2.14823 iter/s, 93.0999s/200 iters), loss = 0.402138
I0902 20:38:38.104423 25873 solver.cpp:261]     Train net output #0: loss = 0.402138 (* 1 = 0.402138 loss)
I0902 20:38:38.104445 25873 sgd_solver.cpp:122] Iteration 400, lr = 0.005
I0902 20:39:22.503720 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:40:12.088577 25873 solver.cpp:242] Iteration 600 (2.128 iter/s, 93.9848s/200 iters), loss = 0.354751
I0902 20:40:12.088690 25873 solver.cpp:261]     Train net output #0: loss = 0.354751 (* 1 = 0.354751 loss)
I0902 20:40:12.088712 25873 sgd_solver.cpp:122] Iteration 600, lr = 0.005
I0902 20:41:48.787137 25873 solver.cpp:242] Iteration 800 (2.06828 iter/s, 96.6989s/200 iters), loss = 0.237767
I0902 20:41:48.787277 25873 solver.cpp:261]     Train net output #0: loss = 0.237767 (* 1 = 0.237767 loss)
I0902 20:41:48.787293 25873 sgd_solver.cpp:122] Iteration 800, lr = 0.005
I0902 20:43:23.112115 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:43:24.979516 25873 solver.cpp:377] Iteration 1000, Testing net (#0)
I0902 20:43:39.402395 25881 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:43:40.002624 25873 solver.cpp:445]     Test net output #0: accuracy = 0.2523
I0902 20:43:40.002652 25873 solver.cpp:445]     Test net output #1: loss = 2.76742 (* 1 = 2.76742 loss)
I0902 20:43:40.002658 25873 solver.cpp:456] ================================
I0902 20:43:40.002661 25873 solver.cpp:457]     Test net best accuracy1 is: 0.2523
I0902 20:43:40.469810 25873 solver.cpp:242] Iteration 1000 (1.79078 iter/s, 111.683s/200 iters), loss = 0.248801
I0902 20:43:40.469856 25873 solver.cpp:261]     Train net output #0: loss = 0.248801 (* 1 = 0.248801 loss)
I0902 20:43:40.469869 25873 sgd_solver.cpp:122] Iteration 1000, lr = 0.005
I0902 20:45:14.052973 25873 solver.cpp:242] Iteration 1200 (2.13713 iter/s, 93.5834s/200 iters), loss = 0.348817
I0902 20:45:14.053098 25873 solver.cpp:261]     Train net output #0: loss = 0.348817 (* 1 = 0.348817 loss)
I0902 20:45:14.053120 25873 sgd_solver.cpp:122] Iteration 1200, lr = 0.005
I0902 20:46:47.928747 25873 solver.cpp:242] Iteration 1400 (2.13047 iter/s, 93.8759s/200 iters), loss = 0.281353
I0902 20:46:47.928902 25873 solver.cpp:261]     Train net output #0: loss = 0.281353 (* 1 = 0.281353 loss)
I0902 20:46:47.928925 25873 sgd_solver.cpp:122] Iteration 1400, lr = 0.005
I0902 20:47:33.240299 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:48:22.795645 25873 solver.cpp:242] Iteration 1600 (2.10822 iter/s, 94.8669s/200 iters), loss = 0.205773
I0902 20:48:22.795760 25873 solver.cpp:261]     Train net output #0: loss = 0.205774 (* 1 = 0.205774 loss)
I0902 20:48:22.795771 25873 sgd_solver.cpp:122] Iteration 1600, lr = 0.005
I0902 20:49:58.191395 25873 solver.cpp:242] Iteration 1800 (2.09653 iter/s, 95.3958s/200 iters), loss = 0.17948
I0902 20:49:58.191527 25873 solver.cpp:261]     Train net output #0: loss = 0.179481 (* 1 = 0.179481 loss)
I0902 20:49:58.191555 25873 sgd_solver.cpp:122] Iteration 1800, lr = 0.005
I0902 20:51:31.799686 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:51:33.680776 25873 solver.cpp:377] Iteration 2000, Testing net (#0)
I0902 20:51:48.195623 25881 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:51:48.797124 25873 solver.cpp:445]     Test net output #0: accuracy = 0.6724
I0902 20:51:48.797169 25873 solver.cpp:445]     Test net output #1: loss = 1.06095 (* 1 = 1.06095 loss)
I0902 20:51:48.797175 25873 solver.cpp:456] ================================
I0902 20:51:48.797178 25873 solver.cpp:457]     Test net best accuracy1 is: 0.6724
I0902 20:51:49.264735 25873 solver.cpp:242] Iteration 2000 (1.80061 iter/s, 111.073s/200 iters), loss = 0.303839
I0902 20:51:49.264788 25873 solver.cpp:261]     Train net output #0: loss = 0.303839 (* 1 = 0.303839 loss)
I0902 20:51:49.264801 25873 sgd_solver.cpp:122] Iteration 2000, lr = 0.005
I0902 20:53:23.760344 25873 solver.cpp:242] Iteration 2200 (2.1165 iter/s, 94.4957s/200 iters), loss = 0.331552
I0902 20:53:23.760469 25873 solver.cpp:261]     Train net output #0: loss = 0.331552 (* 1 = 0.331552 loss)
I0902 20:53:23.760490 25873 sgd_solver.cpp:122] Iteration 2200, lr = 0.005
I0902 20:54:57.269816 25873 solver.cpp:242] Iteration 2400 (2.13882 iter/s, 93.5095s/200 iters), loss = 0.173544
I0902 20:54:57.269887 25873 solver.cpp:261]     Train net output #0: loss = 0.173544 (* 1 = 0.173544 loss)
I0902 20:54:57.269899 25873 sgd_solver.cpp:122] Iteration 2400, lr = 0.005
I0902 20:55:41.839793 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:56:31.447036 25873 solver.cpp:242] Iteration 2600 (2.12365 iter/s, 94.1773s/200 iters), loss = 0.24482
I0902 20:56:31.447183 25873 solver.cpp:261]     Train net output #0: loss = 0.24482 (* 1 = 0.24482 loss)
I0902 20:56:31.447197 25873 sgd_solver.cpp:122] Iteration 2600, lr = 0.005
I0902 20:58:06.523941 25873 solver.cpp:242] Iteration 2800 (2.10356 iter/s, 95.0769s/200 iters), loss = 0.136653
I0902 20:58:06.524014 25873 solver.cpp:261]     Train net output #0: loss = 0.136654 (* 1 = 0.136654 loss)
I0902 20:58:06.524024 25873 sgd_solver.cpp:122] Iteration 2800, lr = 0.005
I0902 20:59:38.282692 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:59:40.148587 25873 solver.cpp:377] Iteration 3000, Testing net (#0)
I0902 20:59:54.546347 25881 data_layer.cpp:73] Restarting data prefetching from start.
I0902 20:59:55.144866 25873 solver.cpp:445]     Test net output #0: accuracy = 0.8227
I0902 20:59:55.144903 25873 solver.cpp:445]     Test net output #1: loss = 0.542231 (* 1 = 0.542231 loss)
I0902 20:59:55.144908 25873 solver.cpp:456] ================================
I0902 20:59:55.144912 25873 solver.cpp:457]     Test net best accuracy1 is: 0.8227
I0902 20:59:55.612323 25873 solver.cpp:242] Iteration 3000 (1.83335 iter/s, 109.09s/200 iters), loss = 0.235899
I0902 20:59:55.612366 25873 solver.cpp:261]     Train net output #0: loss = 0.235899 (* 1 = 0.235899 loss)
I0902 20:59:55.612377 25873 sgd_solver.cpp:122] Iteration 3000, lr = 0.005
I0902 21:01:29.306242 25873 solver.cpp:242] Iteration 3200 (2.13458 iter/s, 93.6953s/200 iters), loss = 0.227561
I0902 21:01:29.306388 25873 solver.cpp:261]     Train net output #0: loss = 0.227561 (* 1 = 0.227561 loss)
I0902 21:01:29.306398 25873 sgd_solver.cpp:122] Iteration 3200, lr = 0.005
I0902 21:03:03.643201 25873 solver.cpp:242] Iteration 3400 (2.12004 iter/s, 94.338s/200 iters), loss = 0.220638
I0902 21:03:03.643364 25873 solver.cpp:261]     Train net output #0: loss = 0.220638 (* 1 = 0.220638 loss)
I0902 21:03:03.643383 25873 sgd_solver.cpp:122] Iteration 3400, lr = 0.005
I0902 21:03:49.808423 25880 data_layer.cpp:73] Restarting data prefetching from start.
I0902 21:04:38.878017 25873 solver.cpp:242] Iteration 3600 (2.10005 iter/s, 95.2358s/200 iters), loss = 0.22474
I0902 21:04:38.878140 25873 solver.cpp:261]     Train net output #0: loss = 0.22474 (* 1 = 0.22474 loss)
I0902 21:04:38.878162 25873 sgd_solver.cpp:122] Iteration 3600, lr = 0.005
I0902 21:06:12.373306 25873 solver.cpp:242] Iteration 3800 (2.13912 iter/s, 93.4962s/200 iters), loss = 0.13033
I0902 21:06:12.373431 25873 solver.cpp:261]     Train net output #0: loss = 0.13033 (* 1 = 0.13033 loss)
I0902 21:06:12.373443 25873 sgd_solver.cpp:122] Iteration 3800, lr = 0.005
